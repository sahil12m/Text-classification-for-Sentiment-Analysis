{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h2>Report HW1 CSCI544</h2>\n",
    "    <h3>Name : Sahil Mondal</h3>\n",
    "    <h3>USC-ID : 5092826451</h3>\n",
    "    <h3>Python Version : 3.9.17</h3>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<p><strong>1. Dataset Preparation</strong></p>\n",
    "<p>For this part my code is preparing a dataset by loading an Amazon product review dataset, keeping only the 'star_rating' and 'review_body' columns by reading a tab-delimited file and skipping to read lines which have formatting issues. \n",
    "It then creates a new 'sentiment_class' column, assigning the value 1 to reviews with ratings 1, 2, or 3, and 2 to reviews with ratings 4 or 5. \n",
    "To balance the classes, I downsample both classes to 50,000 samples each using resample(). \n",
    "Finally, the dataset is split into a training set (80% of the data) and a testing set (20% of the data).</p>\n",
    "\n",
    "<p><strong>2. Data Cleaning</strong></p>\n",
    "<p>For data cleaning I drop rows of data which have nan values anywhere. \n",
    "Additionally, I convert the text_reviews to type 'str' to avoid potential data type issues while parsing the data using beautiful soup. \n",
    "I create a cleaning function where I convert the reviews to lower case first, remove HTML tags(Beautiful soup), remove URLs and non-alphabetic characters(regular expressions), perform contractions(contractions), remove extra spaces(using join()) and finally apply this function to the text_review column of the dataframe. \n",
    "Also I calculate the average review lengths before and after cleaning(character wise).</p>\n",
    "\n",
    "<p><strong>3. Preprocessing</strong></p>\n",
    "<p>For preprocessing, I download the list of stopwords and the wordnetlemmatizer from Natural Language Toolkit(nltk) to create variables of those classes.\n",
    "The stopwords are removed and the text_reviews are lemmatized element-wise to each row in the column which has the cleaned reviews from earlier using a lambda function which serves the purpose of efficient text preprocessing.\n",
    "I calculate the average review lengths before and after preprocessing(character wise).</p>\n",
    "\n",
    "<p><strong>4. Feature Extraction</strong></p>\n",
    "<p>For feature extraction TF-IDF and BagofWords have been used with the help of TfidfVectorizer() and CountVectorizer() functions respectively.\n",
    "I have a used a maximum of 4000 features for both of these feature extraction methods to ensure consistency of number of features and efficiency of computation while calculating the TFIDF sparse matrix, and focusing on the most relevant terms in the text corpus.</p>\n",
    "\n",
    "<p><strong>5. Perceptron</strong></p>\n",
    "<p>For the perceptron model the hyperparameters used for training are the eta0(learning rate), max_iter to limit the maximum iterations, a random seed for consistent accuracy results and early stopping to stop training if the test error curve doesn't improve further. The model is then fit on the BOW features and TFIDF features and predicted on the the test set features to calculate precision, recall and F1 scores.</p>\n",
    "\n",
    "<p><strong>6. SVM</strong></p>\n",
    "<p>For SVM I used LinearSVC() to find a linear decision boundary between classes to train the model for faster results. The random state is fixed, max iterations are fixed. I also used the 'dual' hyperparameter to automatically select a choice between the primal and dual problem optimizations. The rest of the part is similar as done above in the Perceptron.</p>\n",
    "\n",
    "<p><strong>7. Logistic Regression</strong></p>\n",
    "<p>For this part I use the base LogisticRegression() model with hyperparameters of random seed and max_iterations. The rest is similar to the Perceptron model.</p>\n",
    "\n",
    "<p><strong>8. Naive Bayes</strong></p>\n",
    "<p>For this part I used the MultinomialNB() class from sklearn. The rest is similar to the Perceptron model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h2>Code in IPYNB format</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Installing required packages: (Please uncomment the below lines to install the packages)\n",
    "!pip install nltk\n",
    "!pip install bs4\n",
    "!pip install contractions\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "# ! pip install bs4 \n",
    "from bs4 import BeautifulSoup\n",
    "# ! pip install contractions\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')  # For tokenization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data.tsv', sep='\\t', on_bad_lines='skip', index_col=False)\n",
    "\n",
    "# Make an independent copy of the DataFrame\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Keep only 'Reviews' and 'Ratings' columns\n",
    "df = df[['star_rating', 'review_body']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We form two classes and select 50000 reviews randomly from each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class labels: 1 for ratings 1, 2, 3; 2 for ratings 4, 5\n",
    "df['sentiment_class'] = df['star_rating'].apply(lambda x: 1 if x in [1, 2, 3] else 2)\n",
    "\n",
    "# Downsample to 50,000 reviews per class\n",
    "class1_data = resample(df[df['sentiment_class'] == 1], n_samples=50000, random_state=42)\n",
    "class2_data = resample(df[df['sentiment_class'] == 2], n_samples=50000, random_state=42)\n",
    "compressed_data = pd.concat([class1_data, class2_data])\n",
    "\n",
    "# Split dataset into training (80%) and testing (20%)\n",
    "train_df, test_df = train_test_split(compressed_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "train_df['review_body'] = train_df['review_body'].astype(str)\n",
    "test_df['review_body'] = test_df['review_body'].astype(str)\n",
    "\n",
    "\n",
    "def clean_and_preprocess_text(input_text):\n",
    "    # Convert text to lowercase\n",
    "    cleaned_text = input_text.lower()\n",
    "\n",
    "    # Remove HTML tags\n",
    "    cleaned_text = BeautifulSoup(cleaned_text, 'html.parser').get_text()\n",
    "\n",
    "    # Remove URLs\n",
    "    cleaned_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', cleaned_text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove non-alphabetical characters (keep only letters and spaces)\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', cleaned_text)\n",
    "\n",
    "    # Perform contractions (e.g., won't â†’ will not)\n",
    "    cleaned_text = contractions.fix(cleaned_text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "train_df['cleaned_review'] = train_df['review_body'].apply(clean_and_preprocess_text)\n",
    "test_df['cleaned_review'] = test_df['review_body'].apply(clean_and_preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321.35705535276765,304.9250712535627\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate average review length in terms of character length\n",
    "def calculate_average_review_length(reviews_list):\n",
    "    # Calculate the length of each review in the list\n",
    "    review_lengths = [len(review) for review in reviews_list]\n",
    "\n",
    "    # Calculate the average review length\n",
    "    if len(review_lengths) > 0:\n",
    "        average_length = sum(review_lengths) / len(review_lengths)\n",
    "    else:\n",
    "        average_length = 0  # Handle the case when the list is empty\n",
    "\n",
    "    return average_length\n",
    "    \n",
    "# Calculate average length before preprocessing\n",
    "avg_length_before_clean = calculate_average_review_length(train_df['review_body'])\n",
    "avg_length_before_test_clean = calculate_average_review_length(test_df['review_body'])\n",
    "\n",
    "# Calculate average length after preprocessing\n",
    "avg_length_after_clean = calculate_average_review_length(train_df['cleaned_review'])\n",
    "avg_length_after_test_clean = calculate_average_review_length(test_df['cleaned_review'])\n",
    "\n",
    "# Print the results\n",
    "print(f\"{avg_length_before_clean},{avg_length_after_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Apply preprocessing to the 'Cleaned_Reviews' column\n",
    "train_df['preprocessed_reviews'] = train_df['cleaned_review'].apply(lambda review: ' '.join([word for word in review.split() if word.lower() not in stop_words]))\n",
    "test_df['preprocessed_reviews'] = test_df['cleaned_review'].apply(lambda review: ' '.join([word for word in review.split() if word.lower() not in stop_words]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply preprocessing to the 'Cleaned_Reviews' column\n",
    "train_df['preprocessed_reviews'] = train_df['preprocessed_reviews'].apply(lambda review: ' '.join([lemmatizer.lemmatize(word) for word in review.split()]))\n",
    "test_df['preprocessed_reviews'] = test_df['preprocessed_reviews'].apply(lambda review: ' '.join([lemmatizer.lemmatize(word) for word in review.split()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing reviews further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.9250712535627,189.73141157057853\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate average review length in terms of character length\n",
    "def average_review_length(reviews):\n",
    "    lengths = [len(review) for review in reviews]\n",
    "    return sum(lengths) / len(lengths)\n",
    "\n",
    "# Calculate average length before preprocessing\n",
    "avg_length_before = average_review_length(train_df['cleaned_review'])\n",
    "avg_length_before_test = average_review_length(test_df['cleaned_review'])\n",
    "\n",
    "# Calculate average length after preprocessing\n",
    "avg_length_after = average_review_length(train_df['preprocessed_reviews'])\n",
    "avg_length_after_test = average_review_length(test_df['preprocessed_reviews'])\n",
    "\n",
    "# Print the results\n",
    "print(f\"{avg_length_before},{avg_length_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and BoW Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectorizer\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=4000)  # You can adjust max_features as needed\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['preprocessed_reviews'])\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['preprocessed_reviews'])\n",
    "\n",
    "\n",
    "# BoW Vectorizer\n",
    "# Create a BoW vectorizer\n",
    "bow_vectorizer = CountVectorizer(max_features=4000)  # You can adjust max_features as needed\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_bow = bow_vectorizer.fit_transform(train_df['preprocessed_reviews'])\n",
    "\n",
    "# Transform the test data\n",
    "X_test_bow = bow_vectorizer.transform(test_df['preprocessed_reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Using Both Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7945716880234084 0.7847533632286996 0.7896320064173268\n",
      "0.7998933901918976 0.7476831091180867 0.7729075457120782\n"
     ]
    }
   ],
   "source": [
    "# Create a Perceptron model\n",
    "perceptron = Perceptron(eta0=0.001, random_state=42, max_iter=30000, early_stopping=True)\n",
    "\n",
    "# Train the Perceptron model using BoW features\n",
    "perceptron.fit(X_train_bow, train_df['sentiment_class'])\n",
    "\n",
    "# Predict on the training data\n",
    "test_preds_bow = perceptron.predict(X_test_bow)\n",
    "\n",
    "# Calculate precision, recall, and f1-score for BoW\n",
    "precision_bow = precision_score(test_df['sentiment_class'], test_preds_bow)\n",
    "recall_bow = recall_score(test_df['sentiment_class'], test_preds_bow)\n",
    "f1_score_bow = f1_score(test_df['sentiment_class'], test_preds_bow)\n",
    "\n",
    "# Print results for BoW\n",
    "print(precision_bow, recall_bow, f1_score_bow)\n",
    "\n",
    "# Train the Perceptron model using TF-IDF features\n",
    "perceptron.fit(X_train_tfidf, train_df['sentiment_class'])\n",
    "\n",
    "# Predict on the training data\n",
    "test_preds_tfidf = perceptron.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate precision, recall, and f1-score for TF-IDF\n",
    "precision_tfidf = precision_score(test_df['sentiment_class'], test_preds_tfidf)\n",
    "recall_tfidf = recall_score(test_df['sentiment_class'], test_preds_tfidf)\n",
    "f1_score_tfidf = f1_score(test_df['sentiment_class'], test_preds_tfidf)\n",
    "\n",
    "# Print results for TF-IDF\n",
    "print(precision_tfidf, recall_tfidf, f1_score_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Using Both Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8471170033670034 0.8022919780767315 0.8240953989456984\n",
      "0.8351397036889728 0.8369706028898855 0.8360541509058331\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM model\n",
    "svm_classifier = LinearSVC(random_state=42, max_iter=20000, dual='auto')\n",
    "\n",
    "# Train the SVM model using BoW features\n",
    "svm_classifier.fit(X_train_bow, train_df['sentiment_class'])\n",
    "\n",
    "# Predict on the training data\n",
    "test_preds_bow_svm = svm_classifier.predict(X_test_bow)\n",
    "\n",
    "# Calculate precision, recall, and f1-score for BoW with SVM\n",
    "precision_bow_svm = precision_score(test_df['sentiment_class'], test_preds_bow_svm)\n",
    "recall_bow_svm = recall_score(test_df['sentiment_class'], test_preds_bow_svm)\n",
    "f1_score_bow_svm = f1_score(test_df['sentiment_class'], test_preds_bow_svm)\n",
    "\n",
    "# Print results for BoW with SVM\n",
    "print(precision_bow_svm, recall_bow_svm, f1_score_bow_svm)\n",
    "\n",
    "# Train the SVM model using TF-IDF features\n",
    "svm_classifier.fit(X_train_tfidf, train_df['sentiment_class'])\n",
    "\n",
    "# Predict on the training data\n",
    "test_preds_tfidf_svm = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate precision, recall, and f1-score for TF-IDF with SVM\n",
    "precision_tfidf_svm = precision_score(test_df['sentiment_class'], test_preds_tfidf_svm)\n",
    "recall_tfidf_svm = recall_score(test_df['sentiment_class'], test_preds_tfidf_svm)\n",
    "f1_score_tfidf_svm = f1_score(test_df['sentiment_class'], test_preds_tfidf_svm)\n",
    "\n",
    "# Print results for TF-IDF with SVM\n",
    "print(precision_tfidf_svm, recall_tfidf_svm, f1_score_tfidf_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Using Both Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847568578553616 0.8128550074738415 0.8298489241568747\n",
      "0.8362492628268134 0.8478325859491779 0.8420010886238806\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model\n",
    "logistic_regression = LogisticRegression(random_state=42, max_iter=20000)\n",
    "\n",
    "# Train the Logistic Regression model using BoW features\n",
    "logistic_regression.fit(X_train_bow, train_df['sentiment_class'])\n",
    "\n",
    "# Predict on the training data\n",
    "test_preds_bow_lr = logistic_regression.predict(X_test_bow)\n",
    "\n",
    "# Calculate precision, recall, and f1-score for BoW with Logistic Regression\n",
    "precision_bow_lr = precision_score(test_df['sentiment_class'], test_preds_bow_lr)\n",
    "recall_bow_lr = recall_score(test_df['sentiment_class'], test_preds_bow_lr)\n",
    "f1_score_bow_lr = f1_score(test_df['sentiment_class'], test_preds_bow_lr)\n",
    "\n",
    "# Print results for BoW with Logistic Regression\n",
    "print(precision_bow_lr, recall_bow_lr, f1_score_bow_lr)\n",
    "\n",
    "# Train the Logistic Regression model using TF-IDF features\n",
    "logistic_regression.fit(X_train_tfidf, train_df['sentiment_class'])\n",
    "\n",
    "# Predict on the training data\n",
    "test_preds_tfidf_lr = logistic_regression.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate precision, recall, and f1-score for TF-IDF with Logistic Regression\n",
    "precision_tfidf_lr = precision_score(test_df['sentiment_class'], test_preds_tfidf_lr)\n",
    "recall_tfidf_lr = recall_score(test_df['sentiment_class'], test_preds_tfidf_lr)\n",
    "f1_score_tfidf_lr = f1_score(test_df['sentiment_class'], test_preds_tfidf_lr)\n",
    "\n",
    "# Print results for TF-IDF with Logistic Regression\n",
    "print(precision_tfidf_lr, recall_tfidf_lr, f1_score_tfidf_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Using Both Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8405172413793104 0.7384155455904334 0.7861651901755875\n",
      "0.8199210446401458 0.8071748878923767 0.8134980415787888\n"
     ]
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes model\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# Train the Naive Bayes model using BoW features\n",
    "naive_bayes.fit(X_train_bow, train_df['sentiment_class'])\n",
    "\n",
    "# Predict on the training data\n",
    "test_preds_bow_nb = naive_bayes.predict(X_test_bow)\n",
    "\n",
    "# Calculate precision, recall, and f1-score for BoW with Naive Bayes\n",
    "precision_bow_nb = precision_score(test_df['sentiment_class'], test_preds_bow_nb)\n",
    "recall_bow_nb = recall_score(test_df['sentiment_class'], test_preds_bow_nb)\n",
    "f1_score_bow_nb = f1_score(test_df['sentiment_class'], test_preds_bow_nb)\n",
    "\n",
    "# Print results for BoW with Naive Bayes\n",
    "print(precision_bow_nb, recall_bow_nb, f1_score_bow_nb)\n",
    "\n",
    "# Train the Naive Bayes model using TF-IDF features\n",
    "naive_bayes.fit(X_train_tfidf, train_df['sentiment_class'])\n",
    "\n",
    "# Predict on the training data\n",
    "test_preds_tfidf_nb = naive_bayes.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate precision, recall, and f1-score for TF-IDF with Naive Bayes\n",
    "precision_tfidf_nb = precision_score(test_df['sentiment_class'], test_preds_tfidf_nb)\n",
    "recall_tfidf_nb = recall_score(test_df['sentiment_class'], test_preds_tfidf_nb)\n",
    "f1_score_tfidf_nb = f1_score(test_df['sentiment_class'], test_preds_tfidf_nb)\n",
    "\n",
    "# Print results for TF-IDF with Naive Bayes\n",
    "print(precision_tfidf_nb, recall_tfidf_nb, f1_score_tfidf_nb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
